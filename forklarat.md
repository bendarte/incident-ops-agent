ğŸ“˜ Incident Ops Agent â€“ FÃ¶rklaring av Arkitektur
ğŸ§  Ã–versikt
Detta projekt Ã¤r en AI-baserad driftassistent som kÃ¶rs i terminalen.
Den kombinerar:
ğŸ“š Interna dokument (incidentrapporter och runbooks)
ğŸ” Semantisk sÃ¶kning via embeddings (RAG)
ğŸ¤– OpenAI fÃ¶r sprÃ¥kfÃ¶rstÃ¥else och svarsgenerering
ğŸ›  Verktyg (kalkylator, ticket-system)
ğŸ›¡ Guardrails fÃ¶r sÃ¤kerhet
Det Ã¤r inte en vanlig chatbot â€“ det Ã¤r ett system som kan bÃ¥de lÃ¤sa, resonera och agera.
ğŸ” Vad hÃ¤nder nÃ¤r programmet startar?
NÃ¤r du kÃ¶r:
python main.py chat
sker fÃ¶ljande:
Programmet laddar din OpenAI API-nyckel.
Det skapar en koppling till OpenAI-modellen.
Det registrerar alla verktyg (RAG, kalkylator, tickets).
Det startar en interaktiv loop dÃ¤r du kan stÃ¤lla frÃ¥gor.
Agenten Ã¤r nu redo att ta emot kommandon.
ğŸ“ Var finns kunskapen?
All intern kunskap ligger i mappen:
corpus/
Exempel:
corpus/
  incident_db_latency.txt
  runbook_web_cpu_spike.txt
Det Ã¤r dessa filer som agenten anvÃ¤nder fÃ¶r att svara pÃ¥ frÃ¥gor.
OpenAI har inte direkt tillgÃ¥ng till dessa filer.
De lÃ¤ses lokalt av din kod.
ğŸ” Vad Ã¤r RAG?
RAG stÃ¥r fÃ¶r:
Retrieval Augmented Generation
Det betyder:
Systemet letar fÃ¶rst upp relevant information i dina dokument.
Sedan anvÃ¤nder det OpenAI fÃ¶r att formulera ett tydligt svar.
Steg fÃ¶r steg nÃ¤r du frÃ¥gar om latency:
FrÃ¥gan omvandlas till en embedding (en matematisk representation).
FAISS jÃ¤mfÃ¶r den med embeddings frÃ¥n dina dokument.
Den hittar den mest relevanta textbiten.
Den texten skickas till OpenAI.
OpenAI skriver ett tydligt svar baserat pÃ¥ den texten.
Systemet hittar alltsÃ¥ inte pÃ¥ â€“ det arbetar dokumentbaserat.
ğŸ§® Vad Ã¤r embeddings?
Embeddings Ã¤r ett sÃ¤tt att Ã¶versÃ¤tta sprÃ¥k till matematik.
Varje mening omvandlas till en lista med siffror som representerar dess betydelse.
NÃ¤r man stÃ¤ller en frÃ¥ga omvandlas Ã¤ven den till siffror, och systemet letar efter den text som matematiskt ligger nÃ¤rmast frÃ¥gan.
Det Ã¤r sÃ¥ AI:n hittar rÃ¤tt information utan att matcha exakta ord.
ğŸ—„ Vad Ã¤r FAISS?
FAISS Ã¤r en vektordatabas.
Den lagrar embeddings och kan snabbt hitta:
â€œVilken text Ã¤r mest lik den hÃ¤r frÃ¥gan?â€
Det Ã¤r dÃ¤rfÃ¶r systemet kan gÃ¶ra semantisk sÃ¶kning istÃ¤llet fÃ¶r vanlig ordsÃ¶kning.
ğŸ›  Verktyg
Agenten har flera verktyg:
ğŸ“š retrieve_incident_info
SÃ¶ker i corpus/
HÃ¤mtar relevanta textbitar
Returnerar text + kÃ¤llor
ğŸ§® calculate
RÃ¤knar matematiska uttryck
SÃ¤ker implementation (ingen farlig eval)
ğŸ« Ticket-system
Skapar incidenter
HÃ¤mtar status
Uppdaterar status
KrÃ¤ver bekrÃ¤ftelse vid kÃ¤nsliga Ã¥tgÃ¤rder
I projektet Ã¤r tickets simulerade (mockade),
men i en verklig miljÃ¶ skulle dessa anropa riktiga API:er som Jira eller ServiceNow.
ğŸ›¡ Guardrails
Guardrails skyddar systemet frÃ¥n:
Att avslÃ¶ja systemprompt
Att lÃ¤cka hemligheter
Att utfÃ¶ra skadliga kommandon
Det Ã¤r ett sÃ¤kerhetslager mellan anvÃ¤ndaren och modellen.
ğŸ— Arkitektur i lager
Projektet bestÃ¥r av fyra lager:
Data-lager â†’ corpus/
Retrieval-lager â†’ Embeddings + FAISS
Resonemangs-lager â†’ OpenAI
Action-lager â†’ Verktyg (tickets, kalkylator)
Detta Ã¤r en generell AI-agent-arkitektur som kan Ã¥teranvÃ¤ndas i andra projekt.
ğŸ¯ Sammanfattning
Detta projekt Ã¤r en AI-driven incidentassistent som:
LÃ¤ser interna dokument
AnvÃ¤nder semantisk sÃ¶kning
Formulerar svar med OpenAI
Kan agera genom verktyg
Har inbyggd sÃ¤kerhet
Det Ã¤r en mini-version av hur enterprise AI-system byggs i verkligheten.